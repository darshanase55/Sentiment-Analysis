{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequentialvoca\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "# DATASET\n",
    "DATASET_COLUMNS = [\"ids\", 'text', \"target\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.9\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.3, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file: train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yx4247/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "## Training Part\n",
    "dataset_path = os.path.join(\"train.csv\")\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 402755\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 456 ms, sys: 23.3 ms, total: 480 ms\n",
      "Wall time: 196 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Dataset labels distribuition')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 127 ms, total: 17.1 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 362479\n",
      "TEST size: 40276\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "#print(\"TRAIN size:\", len(df_train))\n",
    "#print(\"TEST size:\", len(df_test))\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 117 ms, total: 1.23 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:16:08,364 : INFO : collecting all words and their counts\n",
      "2019-05-17 10:16:08,365 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-17 10:16:08,393 : INFO : PROGRESS: at sentence #10000, processed 93594 words, keeping 11697 word types\n",
      "2019-05-17 10:16:08,422 : INFO : PROGRESS: at sentence #20000, processed 187171 words, keeping 16786 word types\n",
      "2019-05-17 10:16:08,448 : INFO : PROGRESS: at sentence #30000, processed 281514 words, keeping 20814 word types\n",
      "2019-05-17 10:16:08,478 : INFO : PROGRESS: at sentence #40000, processed 373891 words, keeping 24124 word types\n",
      "2019-05-17 10:16:08,514 : INFO : PROGRESS: at sentence #50000, processed 468143 words, keeping 26964 word types\n",
      "2019-05-17 10:16:08,547 : INFO : PROGRESS: at sentence #60000, processed 562236 words, keeping 29448 word types\n",
      "2019-05-17 10:16:08,582 : INFO : PROGRESS: at sentence #70000, processed 656437 words, keeping 31845 word types\n",
      "2019-05-17 10:16:08,624 : INFO : PROGRESS: at sentence #80000, processed 751117 words, keeping 34033 word types\n",
      "2019-05-17 10:16:08,659 : INFO : PROGRESS: at sentence #90000, processed 846064 words, keeping 36070 word types\n",
      "2019-05-17 10:16:08,691 : INFO : PROGRESS: at sentence #100000, processed 939821 words, keeping 37947 word types\n",
      "2019-05-17 10:16:08,720 : INFO : PROGRESS: at sentence #110000, processed 1033797 words, keeping 39753 word types\n",
      "2019-05-17 10:16:08,750 : INFO : PROGRESS: at sentence #120000, processed 1127126 words, keeping 41425 word types\n",
      "2019-05-17 10:16:08,779 : INFO : PROGRESS: at sentence #130000, processed 1221949 words, keeping 43154 word types\n",
      "2019-05-17 10:16:08,813 : INFO : PROGRESS: at sentence #140000, processed 1315886 words, keeping 44762 word types\n",
      "2019-05-17 10:16:08,840 : INFO : PROGRESS: at sentence #150000, processed 1410432 words, keeping 46252 word types\n",
      "2019-05-17 10:16:08,869 : INFO : PROGRESS: at sentence #160000, processed 1504856 words, keeping 47713 word types\n",
      "2019-05-17 10:16:08,897 : INFO : PROGRESS: at sentence #170000, processed 1597959 words, keeping 49162 word types\n",
      "2019-05-17 10:16:08,922 : INFO : PROGRESS: at sentence #180000, processed 1691743 words, keeping 50539 word types\n",
      "2019-05-17 10:16:08,953 : INFO : PROGRESS: at sentence #190000, processed 1785591 words, keeping 51820 word types\n",
      "2019-05-17 10:16:08,983 : INFO : PROGRESS: at sentence #200000, processed 1878831 words, keeping 53136 word types\n",
      "2019-05-17 10:16:09,010 : INFO : PROGRESS: at sentence #210000, processed 1973517 words, keeping 54355 word types\n",
      "2019-05-17 10:16:09,040 : INFO : PROGRESS: at sentence #220000, processed 2067440 words, keeping 55614 word types\n",
      "2019-05-17 10:16:09,069 : INFO : PROGRESS: at sentence #230000, processed 2162828 words, keeping 56892 word types\n",
      "2019-05-17 10:16:09,098 : INFO : PROGRESS: at sentence #240000, processed 2257856 words, keeping 58099 word types\n",
      "2019-05-17 10:16:09,128 : INFO : PROGRESS: at sentence #250000, processed 2352388 words, keeping 59211 word types\n",
      "2019-05-17 10:16:09,156 : INFO : PROGRESS: at sentence #260000, processed 2445928 words, keeping 60294 word types\n",
      "2019-05-17 10:16:09,184 : INFO : PROGRESS: at sentence #270000, processed 2540527 words, keeping 61383 word types\n",
      "2019-05-17 10:16:09,220 : INFO : PROGRESS: at sentence #280000, processed 2635282 words, keeping 62424 word types\n",
      "2019-05-17 10:16:09,263 : INFO : PROGRESS: at sentence #290000, processed 2729149 words, keeping 63465 word types\n",
      "2019-05-17 10:16:09,311 : INFO : PROGRESS: at sentence #300000, processed 2823014 words, keeping 64467 word types\n",
      "2019-05-17 10:16:09,360 : INFO : PROGRESS: at sentence #310000, processed 2915622 words, keeping 65466 word types\n",
      "2019-05-17 10:16:09,397 : INFO : PROGRESS: at sentence #320000, processed 3009405 words, keeping 66382 word types\n",
      "2019-05-17 10:16:09,438 : INFO : PROGRESS: at sentence #330000, processed 3103812 words, keeping 67424 word types\n",
      "2019-05-17 10:16:09,472 : INFO : PROGRESS: at sentence #340000, processed 3197468 words, keeping 68379 word types\n",
      "2019-05-17 10:16:09,504 : INFO : PROGRESS: at sentence #350000, processed 3291944 words, keeping 69384 word types\n",
      "2019-05-17 10:16:09,538 : INFO : PROGRESS: at sentence #360000, processed 3386175 words, keeping 70261 word types\n",
      "2019-05-17 10:16:09,546 : INFO : collected 70519 word types from a corpus of 3409065 raw words and 362479 sentences\n",
      "2019-05-17 10:16:09,547 : INFO : Loading a fresh vocabulary\n",
      "2019-05-17 10:16:09,605 : INFO : effective_min_count=10 retains 14057 unique words (19% of original 70519, drops 56462)\n",
      "2019-05-17 10:16:09,605 : INFO : effective_min_count=10 leaves 3286673 word corpus (96% of original 3409065, drops 122392)\n",
      "2019-05-17 10:16:09,650 : INFO : deleting the raw counts dictionary of 70519 items\n",
      "2019-05-17 10:16:09,653 : INFO : sample=0.001 downsamples 32 most-common words\n",
      "2019-05-17 10:16:09,653 : INFO : downsampling leaves estimated 2793260 word corpus (85.0% of prior 3286673)\n",
      "2019-05-17 10:16:09,691 : INFO : estimated required memory for 14057 words and 300 dimensions: 40765300 bytes\n",
      "2019-05-17 10:16:09,692 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 14057\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:16:09,943 : INFO : training model with 8 workers on 14057 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2019-05-17 10:16:10,970 : INFO : EPOCH 1 - PROGRESS: at 37.25% examples, 1026931 words/s, in_qsize 16, out_qsize 1\n",
      "2019-05-17 10:16:12,002 : INFO : EPOCH 1 - PROGRESS: at 74.43% examples, 1017164 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:16:12,658 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:12,661 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:12,662 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:12,663 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:12,667 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:12,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:12,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:12,688 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:12,689 : INFO : EPOCH - 1 : training on 3409065 raw words (2792972 effective words) took 2.7s, 1022415 effective words/s\n",
      "2019-05-17 10:16:13,718 : INFO : EPOCH 2 - PROGRESS: at 34.04% examples, 944364 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:14,722 : INFO : EPOCH 2 - PROGRESS: at 62.18% examples, 863361 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-17 10:16:15,725 : INFO : EPOCH 2 - PROGRESS: at 89.42% examples, 828925 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:15,970 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:15,973 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:15,975 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:15,982 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:15,989 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:15,992 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:16,001 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:16,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:16,004 : INFO : EPOCH - 2 : training on 3409065 raw words (2793292 effective words) took 3.3s, 848347 effective words/s\n",
      "2019-05-17 10:16:17,024 : INFO : EPOCH 3 - PROGRESS: at 30.22% examples, 841121 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:18,025 : INFO : EPOCH 3 - PROGRESS: at 60.15% examples, 838018 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-17 10:16:19,027 : INFO : EPOCH 3 - PROGRESS: at 88.25% examples, 820042 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:19,341 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:19,345 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:19,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:19,354 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:19,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:19,363 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:19,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:19,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:19,379 : INFO : EPOCH - 3 : training on 3409065 raw words (2793058 effective words) took 3.4s, 831755 effective words/s\n",
      "2019-05-17 10:16:20,410 : INFO : EPOCH 4 - PROGRESS: at 35.21% examples, 964041 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:21,411 : INFO : EPOCH 4 - PROGRESS: at 66.82% examples, 923929 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:22,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:22,389 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:22,393 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:22,401 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:22,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:22,411 : INFO : EPOCH 4 - PROGRESS: at 99.40% examples, 919309 words/s, in_qsize 2, out_qsize 1\n",
      "2019-05-17 10:16:22,412 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:22,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:22,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:22,430 : INFO : EPOCH - 4 : training on 3409065 raw words (2793722 effective words) took 3.0s, 918791 effective words/s\n",
      "2019-05-17 10:16:23,453 : INFO : EPOCH 5 - PROGRESS: at 22.62% examples, 624160 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:24,454 : INFO : EPOCH 5 - PROGRESS: at 53.11% examples, 736928 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:25,462 : INFO : EPOCH 5 - PROGRESS: at 82.92% examples, 767482 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:16:25,880 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:25,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:25,883 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:25,884 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:25,898 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:25,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:25,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:25,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:25,910 : INFO : EPOCH - 5 : training on 3409065 raw words (2793204 effective words) took 3.5s, 805613 effective words/s\n",
      "2019-05-17 10:16:26,933 : INFO : EPOCH 6 - PROGRESS: at 26.40% examples, 734943 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:27,944 : INFO : EPOCH 6 - PROGRESS: at 58.10% examples, 804665 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:28,965 : INFO : EPOCH 6 - PROGRESS: at 92.94% examples, 855343 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:29,105 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:29,108 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:29,109 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:29,112 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:29,117 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:29,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:29,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:29,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:29,140 : INFO : EPOCH - 6 : training on 3409065 raw words (2793330 effective words) took 3.2s, 870092 effective words/s\n",
      "2019-05-17 10:16:30,171 : INFO : EPOCH 7 - PROGRESS: at 27.87% examples, 770291 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:31,181 : INFO : EPOCH 7 - PROGRESS: at 62.19% examples, 859137 words/s, in_qsize 16, out_qsize 1\n",
      "2019-05-17 10:16:32,116 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:32,120 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:32,122 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:32,133 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:32,135 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:32,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:32,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:32,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:16:32,152 : INFO : EPOCH - 7 : training on 3409065 raw words (2793848 effective words) took 3.0s, 933844 effective words/s\n",
      "2019-05-17 10:16:33,172 : INFO : EPOCH 8 - PROGRESS: at 28.75% examples, 799711 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:34,177 : INFO : EPOCH 8 - PROGRESS: at 59.27% examples, 823573 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:35,184 : INFO : EPOCH 8 - PROGRESS: at 86.48% examples, 801216 words/s, in_qsize 14, out_qsize 0\n",
      "2019-05-17 10:16:35,613 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:35,617 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:35,621 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:35,626 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:35,634 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:35,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:35,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:35,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:35,648 : INFO : EPOCH - 8 : training on 3409065 raw words (2793282 effective words) took 3.5s, 802722 effective words/s\n",
      "2019-05-17 10:16:36,683 : INFO : EPOCH 9 - PROGRESS: at 27.28% examples, 751682 words/s, in_qsize 15, out_qsize 1\n",
      "2019-05-17 10:16:37,686 : INFO : EPOCH 9 - PROGRESS: at 56.65% examples, 783686 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:38,703 : INFO : EPOCH 9 - PROGRESS: at 87.66% examples, 807311 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:39,040 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:39,043 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:39,045 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:39,047 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:39,058 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:39,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:39,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:39,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:39,073 : INFO : EPOCH - 9 : training on 3409065 raw words (2793690 effective words) took 3.4s, 820863 effective words/s\n",
      "2019-05-17 10:16:40,098 : INFO : EPOCH 10 - PROGRESS: at 24.94% examples, 688521 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:16:41,102 : INFO : EPOCH 10 - PROGRESS: at 56.94% examples, 787728 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:16:42,129 : INFO : EPOCH 10 - PROGRESS: at 86.18% examples, 791231 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:42,526 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:42,541 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:42,543 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:42,545 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:42,548 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:42,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:42,566 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:42,580 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:42,581 : INFO : EPOCH - 10 : training on 3409065 raw words (2793165 effective words) took 3.5s, 799240 effective words/s\n",
      "2019-05-17 10:16:43,602 : INFO : EPOCH 11 - PROGRESS: at 30.81% examples, 853339 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:44,615 : INFO : EPOCH 11 - PROGRESS: at 70.04% examples, 968552 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:45,377 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:45,386 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:45,390 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:45,399 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:45,401 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:45,403 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:45,407 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:45,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:45,418 : INFO : EPOCH - 11 : training on 3409065 raw words (2792536 effective words) took 2.8s, 989165 effective words/s\n",
      "2019-05-17 10:16:46,433 : INFO : EPOCH 12 - PROGRESS: at 37.84% examples, 1053888 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:47,435 : INFO : EPOCH 12 - PROGRESS: at 75.58% examples, 1053937 words/s, in_qsize 15, out_qsize 1\n",
      "2019-05-17 10:16:48,002 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:48,005 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:48,009 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:48,010 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:48,016 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:48,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:48,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:48,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:48,035 : INFO : EPOCH - 12 : training on 3409065 raw words (2792992 effective words) took 2.6s, 1072296 effective words/s\n",
      "2019-05-17 10:16:49,060 : INFO : EPOCH 13 - PROGRESS: at 37.55% examples, 1042768 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:50,065 : INFO : EPOCH 13 - PROGRESS: at 77.04% examples, 1071724 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:50,582 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:50,589 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:50,592 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:50,595 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:50,597 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:50,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:50,610 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:50,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:50,616 : INFO : EPOCH - 13 : training on 3409065 raw words (2793333 effective words) took 2.6s, 1090898 effective words/s\n",
      "2019-05-17 10:16:51,641 : INFO : EPOCH 14 - PROGRESS: at 37.84% examples, 1044597 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:52,643 : INFO : EPOCH 14 - PROGRESS: at 75.88% examples, 1053238 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:53,328 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:53,334 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:53,342 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:53,348 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:53,349 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:53,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:53,365 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:53,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:53,370 : INFO : EPOCH - 14 : training on 3409065 raw words (2793134 effective words) took 2.7s, 1019294 effective words/s\n",
      "2019-05-17 10:16:54,404 : INFO : EPOCH 15 - PROGRESS: at 37.25% examples, 1021843 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:16:55,417 : INFO : EPOCH 15 - PROGRESS: at 76.17% examples, 1048612 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:16:55,947 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:55,957 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:55,960 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:55,962 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:55,963 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:55,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:55,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:55,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:55,986 : INFO : EPOCH - 15 : training on 3409065 raw words (2792636 effective words) took 2.6s, 1074222 effective words/s\n",
      "2019-05-17 10:16:57,008 : INFO : EPOCH 16 - PROGRESS: at 37.84% examples, 1055281 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:58,008 : INFO : EPOCH 16 - PROGRESS: at 76.46% examples, 1067694 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:16:58,524 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:16:58,526 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:16:58,530 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:16:58,545 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:16:58,546 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:16:58,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:16:58,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:16:58,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:16:58,557 : INFO : EPOCH - 16 : training on 3409065 raw words (2793147 effective words) took 2.6s, 1095070 effective words/s\n",
      "2019-05-17 10:16:59,598 : INFO : EPOCH 17 - PROGRESS: at 37.25% examples, 1020115 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:00,615 : INFO : EPOCH 17 - PROGRESS: at 78.53% examples, 1077217 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:01,109 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:01,111 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:01,113 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:01,115 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:01,132 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:01,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:01,135 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:01,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:01,141 : INFO : EPOCH - 17 : training on 3409065 raw words (2793238 effective words) took 2.6s, 1089523 effective words/s\n",
      "2019-05-17 10:17:02,172 : INFO : EPOCH 18 - PROGRESS: at 27.29% examples, 748780 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:03,176 : INFO : EPOCH 18 - PROGRESS: at 58.98% examples, 814453 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:04,204 : INFO : EPOCH 18 - PROGRESS: at 90.58% examples, 829843 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-17 10:17:04,429 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:04,440 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:04,447 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:04,450 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:04,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:04,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:04,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:04,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:04,475 : INFO : EPOCH - 18 : training on 3409065 raw words (2793187 effective words) took 3.3s, 841267 effective words/s\n",
      "2019-05-17 10:17:05,497 : INFO : EPOCH 19 - PROGRESS: at 34.04% examples, 943038 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:06,507 : INFO : EPOCH 19 - PROGRESS: at 72.67% examples, 1006203 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:07,168 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:07,170 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:07,175 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:07,190 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:07,194 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:07,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:07,197 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:07,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:07,205 : INFO : EPOCH - 19 : training on 3409065 raw words (2792838 effective words) took 2.7s, 1028336 effective words/s\n",
      "2019-05-17 10:17:08,230 : INFO : EPOCH 20 - PROGRESS: at 38.72% examples, 1069555 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:09,232 : INFO : EPOCH 20 - PROGRESS: at 77.34% examples, 1074420 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:09,770 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:09,772 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:09,776 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:09,781 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:09,786 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:09,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:09,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:09,802 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:09,803 : INFO : EPOCH - 20 : training on 3409065 raw words (2793569 effective words) took 2.6s, 1081284 effective words/s\n",
      "2019-05-17 10:17:10,826 : INFO : EPOCH 21 - PROGRESS: at 28.45% examples, 787186 words/s, in_qsize 12, out_qsize 3\n",
      "2019-05-17 10:17:11,829 : INFO : EPOCH 21 - PROGRESS: at 61.60% examples, 854633 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:12,837 : INFO : EPOCH 21 - PROGRESS: at 96.75% examples, 894628 words/s, in_qsize 11, out_qsize 1\n",
      "2019-05-17 10:17:12,875 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:12,879 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:12,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:12,884 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:12,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:12,903 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:12,905 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:12,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:12,915 : INFO : EPOCH - 21 : training on 3409065 raw words (2793733 effective words) took 3.1s, 901373 effective words/s\n",
      "2019-05-17 10:17:13,933 : INFO : EPOCH 22 - PROGRESS: at 37.55% examples, 1047109 words/s, in_qsize 16, out_qsize 0\n",
      "2019-05-17 10:17:14,936 : INFO : EPOCH 22 - PROGRESS: at 77.34% examples, 1078811 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:17:15,492 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:15,495 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:17:15,504 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:15,506 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:15,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:15,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:15,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:15,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:15,523 : INFO : EPOCH - 22 : training on 3409065 raw words (2793638 effective words) took 2.6s, 1077962 effective words/s\n",
      "2019-05-17 10:17:16,541 : INFO : EPOCH 23 - PROGRESS: at 27.28% examples, 758987 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:17,546 : INFO : EPOCH 23 - PROGRESS: at 64.50% examples, 896524 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:18,379 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:18,380 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:18,383 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:18,387 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:18,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:18,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:18,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:18,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:18,415 : INFO : EPOCH - 23 : training on 3409065 raw words (2793258 effective words) took 2.9s, 970630 effective words/s\n",
      "2019-05-17 10:17:19,428 : INFO : EPOCH 24 - PROGRESS: at 34.62% examples, 966071 words/s, in_qsize 13, out_qsize 2\n",
      "2019-05-17 10:17:20,441 : INFO : EPOCH 24 - PROGRESS: at 69.74% examples, 967725 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:21,158 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:21,168 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:21,170 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:21,174 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:21,176 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:21,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:21,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:21,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:21,196 : INFO : EPOCH - 24 : training on 3409065 raw words (2792780 effective words) took 2.8s, 1008619 effective words/s\n",
      "2019-05-17 10:17:22,219 : INFO : EPOCH 25 - PROGRESS: at 38.43% examples, 1068760 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:23,225 : INFO : EPOCH 25 - PROGRESS: at 75.88% examples, 1055498 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:23,866 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:23,874 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:23,875 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:23,878 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:23,883 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:23,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:23,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:23,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:23,902 : INFO : EPOCH - 25 : training on 3409065 raw words (2793536 effective words) took 2.7s, 1039860 effective words/s\n",
      "2019-05-17 10:17:24,926 : INFO : EPOCH 26 - PROGRESS: at 37.55% examples, 1037475 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:25,928 : INFO : EPOCH 26 - PROGRESS: at 72.10% examples, 1001090 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:26,789 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:26,790 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:26,800 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:26,802 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:26,803 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:26,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:26,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:26,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:26,823 : INFO : EPOCH - 26 : training on 3409065 raw words (2793942 effective words) took 2.9s, 960997 effective words/s\n",
      "2019-05-17 10:17:27,842 : INFO : EPOCH 27 - PROGRESS: at 34.34% examples, 952443 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:28,855 : INFO : EPOCH 27 - PROGRESS: at 71.23% examples, 985399 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:29,822 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:29,837 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:29,838 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:29,840 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:29,841 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:29,860 : INFO : EPOCH 27 - PROGRESS: at 99.40% examples, 918051 words/s, in_qsize 2, out_qsize 1\n",
      "2019-05-17 10:17:29,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:29,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:29,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:29,868 : INFO : EPOCH - 27 : training on 3409065 raw words (2792943 effective words) took 3.0s, 921006 effective words/s\n",
      "2019-05-17 10:17:30,889 : INFO : EPOCH 28 - PROGRESS: at 33.75% examples, 934431 words/s, in_qsize 16, out_qsize 1\n",
      "2019-05-17 10:17:31,896 : INFO : EPOCH 28 - PROGRESS: at 70.64% examples, 979410 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:32,559 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:32,567 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:32,570 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:32,571 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:32,577 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:32,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:32,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:32,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:32,594 : INFO : EPOCH - 28 : training on 3409065 raw words (2793296 effective words) took 2.7s, 1029474 effective words/s\n",
      "2019-05-17 10:17:33,607 : INFO : EPOCH 29 - PROGRESS: at 37.55% examples, 1047914 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:34,608 : INFO : EPOCH 29 - PROGRESS: at 76.17% examples, 1063937 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:35,126 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:35,135 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:35,138 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:35,139 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:35,140 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:35,157 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:35,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:17:35,158 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:35,159 : INFO : EPOCH - 29 : training on 3409065 raw words (2793976 effective words) took 2.6s, 1094542 effective words/s\n",
      "2019-05-17 10:17:36,179 : INFO : EPOCH 30 - PROGRESS: at 36.96% examples, 1024676 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:37,183 : INFO : EPOCH 30 - PROGRESS: at 77.94% examples, 1083094 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:37,691 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:37,706 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:37,708 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:37,720 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:37,727 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:37,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:37,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:37,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:37,736 : INFO : EPOCH - 30 : training on 3409065 raw words (2793503 effective words) took 2.6s, 1089618 effective words/s\n",
      "2019-05-17 10:17:38,765 : INFO : EPOCH 31 - PROGRESS: at 36.37% examples, 1006577 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:39,770 : INFO : EPOCH 31 - PROGRESS: at 72.97% examples, 1012577 words/s, in_qsize 15, out_qsize 0\n",
      "2019-05-17 10:17:40,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:40,380 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:40,382 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:40,383 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:40,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:40,397 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:40,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:40,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:40,413 : INFO : EPOCH - 31 : training on 3409065 raw words (2792601 effective words) took 2.7s, 1051095 effective words/s\n",
      "2019-05-17 10:17:41,452 : INFO : EPOCH 32 - PROGRESS: at 32.57% examples, 886278 words/s, in_qsize 14, out_qsize 1\n",
      "2019-05-17 10:17:42,456 : INFO : EPOCH 32 - PROGRESS: at 68.29% examples, 940272 words/s, in_qsize 15, out_qsize 1\n",
      "2019-05-17 10:17:43,205 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-05-17 10:17:43,213 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-05-17 10:17:43,214 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-05-17 10:17:43,215 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-05-17 10:17:43,223 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-05-17 10:17:43,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-17 10:17:43,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-17 10:17:43,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-17 10:17:43,237 : INFO : EPOCH - 32 : training on 3409065 raw words (2793241 effective words) took 2.8s, 993764 effective words/s\n",
      "2019-05-17 10:17:43,238 : INFO : training on a 109090080 raw words (89384620 effective words) took 93.3s, 958062 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min, sys: 3.65 s, total: 7min 4s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(89384620, 109090080)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 70520\n",
      "CPU times: user 6.99 s, sys: 67.1 ms, total: 7.06 s\n",
      "Wall time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.47 s, sys: 352 ms, total: 8.82 s\n",
      "Wall time: 8.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEGATIVE', 'POSITIVE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (362479, 1)\n",
      "y_test (40276, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70520, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:17:59,757 : WARNING : From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:18:00,263 : WARNING : From /Users/yx4247/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          21156000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 21,316,501\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 21,156,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-17 10:18:00,732 : WARNING : From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 326231 samples, validate on 36248 samples\n",
      "Epoch 1/8\n",
      " 55296/326231 [====>.........................] - ETA: 32:13 - loss: 0.4555 - acc: 0.7826"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40276/40276 [==============================] - 72s 2ms/step\n",
      "\n",
      "ACCURACY: 0.9325901282639901\n",
      "LOSS: 0.18520327364070044\n",
      "CPU times: user 5min 38s, sys: 1min 48s, total: 7min 26s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-009b49b152a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
