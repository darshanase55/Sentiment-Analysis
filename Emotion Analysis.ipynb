{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "#Loading the dataset\n",
    "dataset = pd.read_csv(\"emotion.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f19ac88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27383</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110083</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140764</td>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100071</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2837</td>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18231</td>\n",
       "      <td>i find myself frustrated with christians becau...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10714</td>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35177</td>\n",
       "      <td>i feel especially pleased about this as this h...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>122177</td>\n",
       "      <td>i was struggling with these awful feelings and...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26723</td>\n",
       "      <td>i feel so enraged but helpless at the same time</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text emotions\n",
       "0       27383  i feel awful about it too because it s my job ...  sadness\n",
       "1      110083                              im alone i feel awful  sadness\n",
       "2      140764  ive probably mentioned this before but i reall...      joy\n",
       "3      100071           i was feeling a little low few days back  sadness\n",
       "4        2837  i beleive that i am much more sensitive to oth...     love\n",
       "5       18231  i find myself frustrated with christians becau...     love\n",
       "6       10714  i am one of those people who feels like going ...      joy\n",
       "7       35177  i feel especially pleased about this as this h...      joy\n",
       "8      122177  i was struggling with these awful feelings and...      joy\n",
       "9       26723    i feel so enraged but helpless at the same time    anger"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = [text.split(\" \") for text in dataset[\"text\"].values.tolist()]\n",
    "labels = dataset[\"emotions\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'surprise', 1: 'fear', 2: 'sadness', 3: 'love', 4: 'anger', 5: 'joy'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize word2id and label2id dictionaries that will be used to encode words and labels\n",
    "word2id = dict()\n",
    "label2id = dict()\n",
    "\n",
    "max_words = 0 # maximum number of words in a sentence\n",
    "\n",
    "# Construction of word2id dict\n",
    "for sentence in input_sentences:\n",
    "    for word in sentence:\n",
    "        # Add words to word2id dict if not exist\n",
    "        if word not in word2id:\n",
    "            word2id[word] = len(word2id)\n",
    "    # If length of the sentence is greater than max_words, update max_words\n",
    "    if len(sentence) > max_words:\n",
    "        max_words = len(sentence)\n",
    "    \n",
    "# Construction of label2id and id2label dicts\n",
    "label2id = {l: i for i, l in enumerate(set(labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (416809, 178)\n",
      "Shape of Y: (416809, 6)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Encode input words and labels\n",
    "X = [[word2id[word] for word in sentence] for sentence in input_sentences]\n",
    "Y = [label2id[label] for label in labels]\n",
    "\n",
    "# Apply Padding to X\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, max_words)\n",
    "\n",
    "# Convert Y to numpy array\n",
    "Y = keras.utils.to_categorical(Y, num_classes=len(label2id), dtype='float32')\n",
    "\n",
    "# Print shapes\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 178)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 178, 100)     7530300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 178, 100)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 178, 200)     160800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 178, 200)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 178, 1)       201         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 178)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 178)          0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            606         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,712,007\n",
      "Trainable params: 7,712,007\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # The dimension of word embeddings\n",
    "\n",
    "# Define input tensor\n",
    "sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
    "\n",
    "# Word embedding layer\n",
    "embedded_inputs =keras.layers.Embedding(len(word2id) + 1,\n",
    "                                        embedding_dim,\n",
    "                                        input_length=max_words)(sequence_input)\n",
    "\n",
    "# Apply dropout to prevent overfitting\n",
    "embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
    "\n",
    "# Apply Bidirectional LSTM over embedded inputs\n",
    "lstm_outs = keras.layers.wrappers.Bidirectional(\n",
    "    keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
    ")(embedded_inputs)\n",
    "\n",
    "# Apply dropout to LSTM outputs to prevent overfitting\n",
    "lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
    "\n",
    "# Attention Mechanism - Generate attention vectors\n",
    "input_dim = int(lstm_outs.shape[2])\n",
    "permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
    "attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
    "attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
    "attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
    "attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
    "\n",
    "# Last layer: fully connected with softmax activation\n",
    "fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
    "output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
    "\n",
    "# Finally building model\n",
    "model = keras.Model(inputs=[sequence_input], outputs=output)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yx4247/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 375128 samples, validate on 41681 samples\n",
      "Epoch 1/2\n",
      "375128/375128 [==============================] - 2351s 6ms/step - loss: 0.2073 - acc: 0.8975 - val_loss: 0.0920 - val_acc: 0.9403\n",
      "Epoch 2/2\n",
      "375128/375128 [==============================] - 2355s 6ms/step - loss: 0.0914 - acc: 0.9414 - val_loss: 0.0895 - val_acc: 0.9408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb50438cf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=2, batch_size=64, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the model to get attention vectors as well as label prediction\n",
    "model_with_attentions = keras.Model(inputs=model.input,\n",
    "                                    outputs=[model.output, \n",
    "                                             model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Not'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-41e969b4eaa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Encode samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenized_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mencoded_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-41e969b4eaa7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Encode samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtokenized_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mencoded_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Not'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Select random samples to illustrate\n",
    "sample_text = \"Not much my school threw me in here with no warning. I wanted to be in Dual Credit English 3 , but my life has no conscious decisions. Might sound pessimistic but I just want to get out of high school as fast as possible so I can live life. My anxiety about writing terrible essays, bad handwriting, and the fact that I will most likely fail the college course along with the English high-school class.    I am going to be completely honest here: I would beat myself up over and over again. I'm just so used to giving myself a hard time when I screw up. I feel to need to punish myself for not meeting certain standards no matter how realistic or unrealistic they are.  Therapist If I am not failing and I am not constantly stressed out.\"\n",
    "\n",
    "# Encode samples\n",
    "tokenized_sample = sample_text.split(\" \")\n",
    "encoded_samples = [[word2id[word] for word in tokenized_sample]]\n",
    "\n",
    "# Padding\n",
    "encoded_samples = keras.preprocessing.sequence.pad_sequences(encoded_samples, maxlen=max_words)\n",
    "\n",
    "# Make predictions\n",
    "label_probs, attentions = model_with_attentions.predict(encoded_samples)\n",
    "label_probs = {id2label[_id]: prob for (label, _id), prob in zip(label2id.items(),label_probs[0])}\n",
    "\n",
    "# Get word attentions using attenion vector\n",
    "token_attention_dic = {}\n",
    "max_score = 0.0\n",
    "min_score = 0.0\n",
    "for token, attention_score in zip(tokenized_sample, attentions[0][-len(tokenized_sample):]):\n",
    "    token_attention_dic[token] = math.sqrt(attention_score)\n",
    "\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "    \n",
    "def attention2color(attention_score):\n",
    "    r = 255 - int(attention_score * 255)\n",
    "    color = rgb_to_hex((255, r, r))\n",
    "    return str(color)\n",
    "    \n",
    "# Build HTML String to viualize attentions\n",
    "html_text = \"<hr><p style='font-size: large'><b>Text:  </b>\"\n",
    "for token, attention in token_attention_dic.items():\n",
    "    html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention),\n",
    "                                                                        token)\n",
    "html_text += \"</p>\"\n",
    "# Display text enriched with attention scores \n",
    "display(HTML(html_text))\n",
    "\n",
    "# PLOT EMOTION SCORES\n",
    "emotions = [label for label, _ in label_probs.items()]\n",
    "scores = [score for _, score in label_probs.items()]\n",
    "plt.figure(figsize=(5,2))\n",
    "plt.bar(np.arange(len(emotions)), scores, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan', \"purple\"])\n",
    "plt.xticks(np.arange(len(emotions)), emotions)\n",
    "plt.ylabel('Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have had to choose to give those feelings and terrible moments of indecisiveness over to god'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not',\n",
       " 'much',\n",
       " 'my',\n",
       " 'school',\n",
       " 'threw',\n",
       " 'me',\n",
       " 'in',\n",
       " 'here',\n",
       " 'with',\n",
       " 'no',\n",
       " 'warning.',\n",
       " 'I',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Dual',\n",
       " 'Credit',\n",
       " 'English',\n",
       " '3',\n",
       " ',',\n",
       " 'but',\n",
       " 'my',\n",
       " 'life',\n",
       " 'has',\n",
       " 'no',\n",
       " 'conscious',\n",
       " 'decisions.',\n",
       " 'Might',\n",
       " 'sound',\n",
       " 'pessimistic',\n",
       " 'but',\n",
       " 'I',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'get',\n",
       " 'out',\n",
       " 'of',\n",
       " 'high',\n",
       " 'school',\n",
       " 'as',\n",
       " 'fast',\n",
       " 'as',\n",
       " 'possible',\n",
       " 'so',\n",
       " 'I',\n",
       " 'can',\n",
       " 'live',\n",
       " 'life.',\n",
       " 'My',\n",
       " 'anxiety',\n",
       " 'about',\n",
       " 'writing',\n",
       " 'terrible',\n",
       " 'essays,',\n",
       " 'bad',\n",
       " 'handwriting,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'I',\n",
       " 'will',\n",
       " 'most',\n",
       " 'likely',\n",
       " 'fail',\n",
       " 'the',\n",
       " 'college',\n",
       " 'course',\n",
       " 'along',\n",
       " 'with',\n",
       " 'the',\n",
       " 'English',\n",
       " 'high-school',\n",
       " 'class.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'completely',\n",
       " 'honest',\n",
       " 'here:',\n",
       " 'I',\n",
       " 'would',\n",
       " 'beat',\n",
       " 'myself',\n",
       " 'up',\n",
       " 'over',\n",
       " 'and',\n",
       " 'over',\n",
       " 'again.',\n",
       " \"I'm\",\n",
       " 'just',\n",
       " 'so',\n",
       " 'used',\n",
       " 'to',\n",
       " 'giving',\n",
       " 'myself',\n",
       " 'a',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'when',\n",
       " 'I',\n",
       " 'screw',\n",
       " 'up.',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'to',\n",
       " 'need',\n",
       " 'to',\n",
       " 'punish',\n",
       " 'myself',\n",
       " 'for',\n",
       " 'not',\n",
       " 'meeting',\n",
       " 'certain',\n",
       " 'standards',\n",
       " 'no',\n",
       " 'matter',\n",
       " 'how',\n",
       " 'realistic',\n",
       " 'or',\n",
       " 'unrealistic',\n",
       " 'they',\n",
       " 'are.',\n",
       " '',\n",
       " 'Therapist',\n",
       " 'If',\n",
       " 'I',\n",
       " 'am',\n",
       " 'not',\n",
       " 'failing',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'not',\n",
       " 'constantly',\n",
       " 'stressed',\n",
       " 'out.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 0,\n",
       " 'feel': 1,\n",
       " 'awful': 2,\n",
       " 'about': 3,\n",
       " 'it': 4,\n",
       " 'too': 5,\n",
       " 'because': 6,\n",
       " 's': 7,\n",
       " 'my': 8,\n",
       " 'job': 9,\n",
       " 'to': 10,\n",
       " 'get': 11,\n",
       " 'him': 12,\n",
       " 'in': 13,\n",
       " 'a': 14,\n",
       " 'position': 15,\n",
       " 'succeed': 16,\n",
       " 'and': 17,\n",
       " 'just': 18,\n",
       " 'didn': 19,\n",
       " 't': 20,\n",
       " 'happen': 21,\n",
       " 'here': 22,\n",
       " 'im': 23,\n",
       " 'alone': 24,\n",
       " 'ive': 25,\n",
       " 'probably': 26,\n",
       " 'mentioned': 27,\n",
       " 'this': 28,\n",
       " 'before': 29,\n",
       " 'but': 30,\n",
       " 'really': 31,\n",
       " 'do': 32,\n",
       " 'proud': 33,\n",
       " 'of': 34,\n",
       " 'myself': 35,\n",
       " 'for': 36,\n",
       " 'actually': 37,\n",
       " 'keeping': 38,\n",
       " 'up': 39,\n",
       " 'with': 40,\n",
       " 'new': 41,\n",
       " 'years': 42,\n",
       " 'resolution': 43,\n",
       " 'monthly': 44,\n",
       " 'weekly': 45,\n",
       " 'goals': 46,\n",
       " 'was': 47,\n",
       " 'feeling': 48,\n",
       " 'little': 49,\n",
       " 'low': 50,\n",
       " 'few': 51,\n",
       " 'days': 52,\n",
       " 'back': 53,\n",
       " 'beleive': 54,\n",
       " 'that': 55,\n",
       " 'am': 56,\n",
       " 'much': 57,\n",
       " 'more': 58,\n",
       " 'sensitive': 59,\n",
       " 'other': 60,\n",
       " 'peoples': 61,\n",
       " 'feelings': 62,\n",
       " 'tend': 63,\n",
       " 'be': 64,\n",
       " 'compassionate': 65,\n",
       " 'find': 66,\n",
       " 'frustrated': 67,\n",
       " 'christians': 68,\n",
       " 'there': 69,\n",
       " 'is': 70,\n",
       " 'constantly': 71,\n",
       " 'talk': 72,\n",
       " 'loving': 73,\n",
       " 'one': 74,\n",
       " 'another': 75,\n",
       " 'being': 76,\n",
       " 'each': 77,\n",
       " 'praying': 78,\n",
       " 'have': 79,\n",
       " 'seen': 80,\n",
       " 'not': 81,\n",
       " 'always': 82,\n",
       " 'the': 83,\n",
       " 'case': 84,\n",
       " 'those': 85,\n",
       " 'people': 86,\n",
       " 'who': 87,\n",
       " 'feels': 88,\n",
       " 'like': 89,\n",
       " 'going': 90,\n",
       " 'gym': 91,\n",
       " 'only': 92,\n",
       " 'worthwhile': 93,\n",
       " 'if': 94,\n",
       " 'you': 95,\n",
       " 'can': 96,\n",
       " 'an': 97,\n",
       " 'hour': 98,\n",
       " 'or': 99,\n",
       " 'especially': 100,\n",
       " 'pleased': 101,\n",
       " 'as': 102,\n",
       " 'has': 103,\n",
       " 'been': 104,\n",
       " 'long': 105,\n",
       " 'time': 106,\n",
       " 'coming': 107,\n",
       " 'struggling': 108,\n",
       " 'these': 109,\n",
       " 'saying': 110,\n",
       " 'such': 111,\n",
       " 'sweet': 112,\n",
       " 'things': 113,\n",
       " 'deserving': 114,\n",
       " 'sisters': 115,\n",
       " 'friendship': 116,\n",
       " 'we': 117,\n",
       " 'agreed': 118,\n",
       " 'well': 119,\n",
       " 'she': 120,\n",
       " 'her': 121,\n",
       " 'car': 122,\n",
       " 'starting': 123,\n",
       " 'drive': 124,\n",
       " 'away': 125,\n",
       " 'when': 126,\n",
       " 'reached': 127,\n",
       " 'out': 128,\n",
       " 'hand': 129,\n",
       " 'so': 130,\n",
       " 'enraged': 131,\n",
       " 'helpless': 132,\n",
       " 'at': 133,\n",
       " 'same': 134,\n",
       " 'said': 135,\n",
       " 'bit': 136,\n",
       " 'rebellious': 137,\n",
       " 'also': 138,\n",
       " 'disillusioned': 139,\n",
       " 'someone': 140,\n",
       " 'claimed': 141,\n",
       " 'value': 142,\n",
       " 'truth': 143,\n",
       " 'fraud': 144,\n",
       " 'mean': 145,\n",
       " 'on': 146,\n",
       " 'stupid': 147,\n",
       " 'trip': 148,\n",
       " 'making': 149,\n",
       " 'great': 150,\n",
       " 'album': 151,\n",
       " 'are': 152,\n",
       " 'ecstatic': 153,\n",
       " 'woke': 154,\n",
       " 'particularly': 155,\n",
       " 'vile': 156,\n",
       " 'tried': 157,\n",
       " 'ignore': 158,\n",
       " 'got': 159,\n",
       " 'worse': 160,\n",
       " 'could': 161,\n",
       " 'moth': 162,\n",
       " 'burrowing': 163,\n",
       " 'its': 164,\n",
       " 'way': 165,\n",
       " 'into': 166,\n",
       " 'brain': 167,\n",
       " 'seeking': 168,\n",
       " 'means': 169,\n",
       " 'control': 170,\n",
       " 'enslave': 171,\n",
       " 'me': 172,\n",
       " 'nasty': 173,\n",
       " 'bug': 174,\n",
       " 'did': 175,\n",
       " 'chekov': 176,\n",
       " 'star': 177,\n",
       " 'trek': 178,\n",
       " 'wrath': 179,\n",
       " 'khan': 180,\n",
       " 'know': 181,\n",
       " 'doing': 182,\n",
       " 'doesnt': 183,\n",
       " 'thoughts': 184,\n",
       " 'jingle': 185,\n",
       " 'does': 186,\n",
       " 'end': 187,\n",
       " 'every': 188,\n",
       " 'cycle': 189,\n",
       " 'makes': 190,\n",
       " 'seem': 191,\n",
       " 'excited': 192,\n",
       " 'done': 193,\n",
       " 'load': 194,\n",
       " 'cant': 195,\n",
       " 'help': 196,\n",
       " 'sing': 197,\n",
       " 'wish': 198,\n",
       " 'knew': 199,\n",
       " 'word': 200,\n",
       " 'write': 201,\n",
       " 'think': 202,\n",
       " 'useless': 203,\n",
       " 'm': 204,\n",
       " 'heartless': 205,\n",
       " 'empty': 206,\n",
       " 'w': 207,\n",
       " 'weird': 208,\n",
       " 'knowing': 209,\n",
       " 'mine': 210,\n",
       " 'died': 211,\n",
       " 'wasn': 212,\n",
       " 'around': 213,\n",
       " 'assured': 214,\n",
       " 'no': 215,\n",
       " 'thing': 216,\n",
       " 'ultimate': 217,\n",
       " 'forgetting': 218,\n",
       " 'traces': 219,\n",
       " 'once': 220,\n",
       " 'impressed': 221,\n",
       " 'upon': 222,\n",
       " 'memory': 223,\n",
       " 'indestructible': 224,\n",
       " 'blessed': 225,\n",
       " 'everyday': 226,\n",
       " 'our': 227,\n",
       " 'man': 228,\n",
       " 'love': 229,\n",
       " 'watch': 230,\n",
       " 'grow': 231,\n",
       " 'exhausted': 232,\n",
       " 'go': 233,\n",
       " 'home': 234,\n",
       " 'glad': 235,\n",
       " 'learning': 236,\n",
       " 'others': 237,\n",
       " 'learn': 238,\n",
       " 'stil': 239,\n",
       " 'see': 240,\n",
       " 'kaibas': 241,\n",
       " 'face': 242,\n",
       " 'tv': 243,\n",
       " 'screen': 244,\n",
       " 'still': 245,\n",
       " 'amateur': 246,\n",
       " 'duelists': 247,\n",
       " 'prowling': 248,\n",
       " 'good': 249,\n",
       " 'side': 250,\n",
       " 'city': 251,\n",
       " 'urge': 252,\n",
       " 'throttle': 253,\n",
       " 'all': 254,\n",
       " 'idiotic': 255,\n",
       " 'mortals': 256,\n",
       " 'dare': 257,\n",
       " 'look': 258,\n",
       " 'eye': 259,\n",
       " 'don': 260,\n",
       " 'uncomfortable': 261,\n",
       " 'quiet': 262,\n",
       " 'left': 263,\n",
       " 'kinda': 264,\n",
       " 'insecure': 265,\n",
       " 'alternate': 266,\n",
       " 'between': 267,\n",
       " 'sympathetic': 268,\n",
       " 'toward': 269,\n",
       " 'humanity': 270,\n",
       " 'misanthrope': 271,\n",
       " 'pretty': 272,\n",
       " 'bad': 273,\n",
       " 'last': 274,\n",
       " 'two': 275,\n",
       " 'books': 276,\n",
       " 'will': 277,\n",
       " 'rushed': 278,\n",
       " 'terms': 279,\n",
       " 'story': 280,\n",
       " 'sincerely': 281,\n",
       " 'believe': 282,\n",
       " 'client': 283,\n",
       " 'celebrity': 284,\n",
       " 'deserves': 285,\n",
       " 'full': 286,\n",
       " 'attention': 287,\n",
       " 'leaves': 288,\n",
       " 'glamorous': 289,\n",
       " 'than': 290,\n",
       " 'they': 291,\n",
       " 'arrived': 292,\n",
       " 'comfortable': 293,\n",
       " 'happy': 294,\n",
       " 'burdened': 295,\n",
       " 'consumed': 296,\n",
       " 'dead': 297,\n",
       " 'yet': 298,\n",
       " 'without': 299,\n",
       " 'humiliated': 300,\n",
       " 'continually': 301,\n",
       " 'surprised': 302,\n",
       " 'how': 303,\n",
       " 'less': 304,\n",
       " 'need': 305,\n",
       " 'eat': 306,\n",
       " 'truly': 307,\n",
       " 'satisfied': 308,\n",
       " 'eating': 309,\n",
       " 'food': 310,\n",
       " 'sitting': 311,\n",
       " 'down': 312,\n",
       " 'whole': 313,\n",
       " 'lovely': 314,\n",
       " 'experience': 315,\n",
       " 'meal': 316,\n",
       " 'satisfying': 317,\n",
       " 'soul': 318,\n",
       " 'stomach': 319,\n",
       " 'waddled': 320,\n",
       " 'hospital': 321,\n",
       " 'lightheaded': 322,\n",
       " 'ok': 323,\n",
       " 'apologize': 324,\n",
       " 'almost': 325,\n",
       " 'day': 326,\n",
       " 'lack': 327,\n",
       " 'faith': 328,\n",
       " 'ask': 329,\n",
       " 'give': 330,\n",
       " 'uncertain': 331,\n",
       " 'future': 332,\n",
       " 'kiev': 333,\n",
       " 'searching': 334,\n",
       " 'direction': 335,\n",
       " 'least': 336,\n",
       " 'now': 337,\n",
       " 'slightly': 338,\n",
       " 'hopeful': 339,\n",
       " 'angry': 340,\n",
       " 'through': 341,\n",
       " 'life': 342,\n",
       " 'carefree': 343,\n",
       " 'want': 344,\n",
       " 'passionate': 345,\n",
       " 'today': 346,\n",
       " 'having': 347,\n",
       " 'week': 348,\n",
       " 'where': 349,\n",
       " 'depressed': 350,\n",
       " 'seriously': 351,\n",
       " 'anxious': 352,\n",
       " 'article': 353,\n",
       " 'published': 354,\n",
       " 'clearly': 355,\n",
       " 'depth': 356,\n",
       " 'peace': 357,\n",
       " 'unsure': 358,\n",
       " 'relax': 359,\n",
       " 'he': 360,\n",
       " 'wouldn': 361,\n",
       " 'friendly': 362,\n",
       " 'tear': 363,\n",
       " 'off': 364,\n",
       " 'strip': 365,\n",
       " 'mind': 366,\n",
       " 'working': 367,\n",
       " 'overtime': 368,\n",
       " 'trying': 369,\n",
       " 'work': 370,\n",
       " 'what': 371,\n",
       " 'doubtful': 372,\n",
       " 'place': 373,\n",
       " 'world': 374,\n",
       " 'technology': 375,\n",
       " 'applicable': 376,\n",
       " 'often': 377,\n",
       " 'helpful': 378,\n",
       " 'doug': 379,\n",
       " 'engelbart': 380,\n",
       " 'listening': 381,\n",
       " 'describe': 382,\n",
       " 'many': 383,\n",
       " 'interviews': 384,\n",
       " 'his': 385,\n",
       " 'genesis': 386,\n",
       " 'dogged': 387,\n",
       " 'perseverance': 388,\n",
       " 'meeting': 389,\n",
       " 'plan': 390,\n",
       " 'rotten': 391,\n",
       " 'dont': 392,\n",
       " 'post': 393,\n",
       " 'material': 394,\n",
       " 'shouldnt': 395,\n",
       " 'reading': 396,\n",
       " 'youre': 397,\n",
       " 'theyre': 398,\n",
       " 'thrilled': 399,\n",
       " 'shitty': 400,\n",
       " 'mood': 401,\n",
       " 'past': 402,\n",
       " 'even': 403,\n",
       " 'imagine': 404,\n",
       " 'mom': 405,\n",
       " 'three': 406,\n",
       " 'younger': 407,\n",
       " 'must': 408,\n",
       " 'death': 409,\n",
       " 'from': 410,\n",
       " 'early': 411,\n",
       " 'age': 412,\n",
       " 'associate': 413,\n",
       " 'something': 414,\n",
       " 'evil': 415,\n",
       " 'tragic': 416,\n",
       " 'law': 417,\n",
       " 'journey': 418,\n",
       " 'start': 419,\n",
       " 'weekend': 420,\n",
       " 'sojourn': 421,\n",
       " 'pines': 422,\n",
       " 'most': 423,\n",
       " 'likely': 424,\n",
       " 'overwhelmed': 425,\n",
       " 'again': 426,\n",
       " 'reaching': 427,\n",
       " 'extending': 428,\n",
       " 'space': 429,\n",
       " 'touch': 430,\n",
       " 'beloved': 431,\n",
       " 'looking': 432,\n",
       " 'right': 433,\n",
       " 'desperately': 434,\n",
       " 'creative': 435,\n",
       " 'project': 436,\n",
       " 'had': 437,\n",
       " 'sit': 438,\n",
       " 'fucking': 439,\n",
       " 'mother': 440,\n",
       " 'fucker': 441,\n",
       " 'fuckity': 442,\n",
       " 'fuckers': 443,\n",
       " 'fucked': 444,\n",
       " 'play': 445,\n",
       " 'anything': 446,\n",
       " 'else': 447,\n",
       " 'hoping': 448,\n",
       " 'target': 449,\n",
       " 'soon': 450,\n",
       " 'positive': 451,\n",
       " 'appreciative': 452,\n",
       " 'talent': 453,\n",
       " 'suck': 454,\n",
       " 'stop': 455,\n",
       " 'breathing': 456,\n",
       " 'stressed': 457,\n",
       " 'sickened': 458,\n",
       " 'by': 459,\n",
       " 'disgusted': 460,\n",
       " 'sins': 461,\n",
       " 'despite': 462,\n",
       " 'divinity': 463,\n",
       " 'nothing': 464,\n",
       " 'smart': 465,\n",
       " 'interesting': 466,\n",
       " 'grateful': 467,\n",
       " 'very': 468,\n",
       " 'towards': 469,\n",
       " 'them': 470,\n",
       " 'fix': 471,\n",
       " 'their': 472,\n",
       " 'own': 473,\n",
       " 'problems': 474,\n",
       " 'figure': 475,\n",
       " 'parts': 476,\n",
       " 'take': 477,\n",
       " 'emergency': 478,\n",
       " 'appointment': 479,\n",
       " 'yesterday': 480,\n",
       " 'defeated': 481,\n",
       " 'isnt': 482,\n",
       " 'true': 483,\n",
       " 'sometimes': 484,\n",
       " 'unimportant': 485,\n",
       " 'insignificant': 486,\n",
       " 'person': 487,\n",
       " 'earth': 488,\n",
       " 'numb': 489,\n",
       " 'everything': 490,\n",
       " 'hard': 491,\n",
       " 'express': 492,\n",
       " 'exactly': 493,\n",
       " 'went': 494,\n",
       " 'harrison': 495,\n",
       " 'walk': 496,\n",
       " 'nonetheless': 497,\n",
       " 'clear': 498,\n",
       " 'heads': 499,\n",
       " 'brave': 500,\n",
       " 'incredibly': 501,\n",
       " 'thankful': 502,\n",
       " 'year': 503,\n",
       " 'children': 504,\n",
       " 'sipping': 505,\n",
       " 'martini': 506,\n",
       " 'which': 507,\n",
       " 'why': 508,\n",
       " 'generous': 509,\n",
       " 'would': 510,\n",
       " 'recommend': 511,\n",
       " 'watching': 512,\n",
       " 'amazed': 513,\n",
       " 'inspired': 514,\n",
       " 'put': 515,\n",
       " 'eloquent': 516,\n",
       " 'words': 517,\n",
       " 'say': 518,\n",
       " 'listless': 519,\n",
       " 'meaningless': 520,\n",
       " 'though': 521,\n",
       " 've': 522,\n",
       " 'failed': 523,\n",
       " 'funny': 524,\n",
       " 'already': 525,\n",
       " 'happened': 526,\n",
       " 'needed': 527,\n",
       " 'hear': 528,\n",
       " 'divine': 529,\n",
       " 'strong': 530,\n",
       " 'fairly': 531,\n",
       " 'authentic': 532,\n",
       " 'generally': 533,\n",
       " 'honest': 534,\n",
       " 'opinions': 535,\n",
       " 'desires': 536,\n",
       " 'etc': 537,\n",
       " 'never': 538,\n",
       " 'lie': 539,\n",
       " 'white': 540,\n",
       " 'lies': 541,\n",
       " 'comes': 542,\n",
       " 'deep': 543,\n",
       " 'dark': 544,\n",
       " 'close': 545,\n",
       " 'negative': 546,\n",
       " 'your': 547,\n",
       " 'gut': 548,\n",
       " 'oh': 549,\n",
       " 'repressed': 550,\n",
       " 'fear': 551,\n",
       " 'slept': 552,\n",
       " 'horribly': 553,\n",
       " 'manage': 554,\n",
       " 'save': 555,\n",
       " 'money': 556,\n",
       " 'times': 557,\n",
       " 'supposed': 558,\n",
       " 'read': 559,\n",
       " 'bible': 560,\n",
       " 'god': 561,\n",
       " 'wants': 562,\n",
       " 'peaceful': 563,\n",
       " 'thats': 564,\n",
       " 'hated': 565,\n",
       " 'growing': 566,\n",
       " 'memories': 567,\n",
       " 'innocent': 568,\n",
       " 'child': 569,\n",
       " 'worthlessness': 570,\n",
       " 'consume': 571,\n",
       " 'badly': 572,\n",
       " 'cannot': 573,\n",
       " 'wear': 574,\n",
       " 'causing': 575,\n",
       " 'spasms': 576,\n",
       " 'diarrhea': 577,\n",
       " 'mouthfuls': 578,\n",
       " 'miserable': 579,\n",
       " 'kid': 580,\n",
       " 'brother': 581,\n",
       " 'broke': 582,\n",
       " 'spectacles': 583,\n",
       " 'mouth': 584,\n",
       " 'water': 585,\n",
       " 'devoted': 586,\n",
       " 'energy': 587,\n",
       " 'evoking': 588,\n",
       " 'yelps': 589,\n",
       " 'lips': 590,\n",
       " 'may': 591,\n",
       " 'terminology': 592,\n",
       " 'thus': 593,\n",
       " 'improve': 594,\n",
       " 'ability': 595,\n",
       " 'communicate': 596,\n",
       " 'afraid': 597,\n",
       " 'nurse': 598,\n",
       " 'confident': 599,\n",
       " 'kids': 600,\n",
       " 'teach': 601,\n",
       " 'scared': 602,\n",
       " 'cute': 603,\n",
       " 'church': 604,\n",
       " 'sunday': 605,\n",
       " 'thought': 606,\n",
       " 'itd': 607,\n",
       " 'belly': 608,\n",
       " 'picture': 609,\n",
       " 'yuchun': 610,\n",
       " 'junsu': 611,\n",
       " 'remorseful': 612,\n",
       " 'regretful': 613,\n",
       " 'associated': 614,\n",
       " 'protest': 615,\n",
       " 'whilst': 616,\n",
       " 'reaping': 617,\n",
       " 'benefits': 618,\n",
       " 'relatively': 619,\n",
       " 'society': 620,\n",
       " 'pressured': 621,\n",
       " 'induce': 622,\n",
       " 'remain': 623,\n",
       " 'pressure': 624,\n",
       " 'frolicking': 625,\n",
       " 'precious': 626,\n",
       " 'some': 627,\n",
       " 'useful': 628,\n",
       " 'tools': 629,\n",
       " 'kind': 630,\n",
       " 'defective': 631,\n",
       " 'shell': 632,\n",
       " 'prevents': 633,\n",
       " 'utilizing': 634,\n",
       " 'using': 635,\n",
       " 'given': 636,\n",
       " 'suppose': 637,\n",
       " 'genuinely': 638,\n",
       " 'characters': 639,\n",
       " 'keen': 640,\n",
       " 'uncover': 641,\n",
       " 'part': 642,\n",
       " 'adventurous': 643,\n",
       " 'might': 644,\n",
       " 'toss': 645,\n",
       " 'scoop': 646,\n",
       " 'protein': 647,\n",
       " 'powder': 648,\n",
       " 'extra': 649,\n",
       " 'punch': 650,\n",
       " 'nutrition': 651,\n",
       " 'awkward': 652,\n",
       " 'rose': 653,\n",
       " 'greedy': 654,\n",
       " 'book': 655,\n",
       " 'ending': 656,\n",
       " 'liked': 657,\n",
       " 'except': 658,\n",
       " 'hes': 659,\n",
       " 'missed': 660,\n",
       " 'talking': 661,\n",
       " 'snobbish': 662,\n",
       " 'uppity': 663,\n",
       " 'accent': 664,\n",
       " 'responding': 665,\n",
       " 'let': 666,\n",
       " 'lot': 667,\n",
       " 'while': 668,\n",
       " 'flipping': 669,\n",
       " 'hair': 670,\n",
       " 'then': 671,\n",
       " 'pull': 672,\n",
       " 'cheese': 673,\n",
       " 'wiz': 674,\n",
       " 'needy': 675,\n",
       " 'desperate': 676,\n",
       " 'prove': 677,\n",
       " 'mum': 678,\n",
       " 'carries': 679,\n",
       " 'everyone': 680,\n",
       " 'outgoing': 681,\n",
       " 'naturally': 682,\n",
       " 'discouraged': 683,\n",
       " 'friend': 684,\n",
       " 'shared': 685,\n",
       " 'verse': 686,\n",
       " 'hope': 687,\n",
       " 'fill': 688,\n",
       " 'joy': 689,\n",
       " 'trust': 690,\n",
       " 'overflow': 691,\n",
       " 'power': 692,\n",
       " 'holy': 693,\n",
       " 'spirit': 694,\n",
       " 'try': 695,\n",
       " 'dismissive': 696,\n",
       " 'elections': 697,\n",
       " 'since': 698,\n",
       " 'privileged': 699,\n",
       " 'election': 700,\n",
       " 'half': 701,\n",
       " 'races': 702,\n",
       " 'ballot': 703,\n",
       " 'folks': 704,\n",
       " 'running': 705,\n",
       " 'completely': 706,\n",
       " 'unopposed': 707,\n",
       " 'quite': 708,\n",
       " 'distressed': 709,\n",
       " 'approaching': 710,\n",
       " 'concern': 711,\n",
       " 'foolish': 712,\n",
       " 'ashamed': 713,\n",
       " 'ish': 714,\n",
       " 'decided': 715,\n",
       " 'carry': 716,\n",
       " 'group': 717,\n",
       " 'set': 718,\n",
       " 'later': 719,\n",
       " 'were': 720,\n",
       " 'catching': 721,\n",
       " 'us': 722,\n",
       " 'quickly': 723,\n",
       " 'embarrassed': 724,\n",
       " 'wise': 725,\n",
       " 'labyrinths': 726,\n",
       " 'approached': 727,\n",
       " 'solemn': 728,\n",
       " 'purposes': 729,\n",
       " 'hate': 730,\n",
       " 'better': 731,\n",
       " 'make': 732,\n",
       " 'agitated': 733,\n",
       " 'volcanos': 734,\n",
       " 'sudden': 735,\n",
       " 'movement': 736,\n",
       " 'thinking': 737,\n",
       " 'realise': 738,\n",
       " 'date': 739,\n",
       " 'alarmed': 740,\n",
       " 'living': 741,\n",
       " 'everybody': 742,\n",
       " 'eager': 743,\n",
       " 'competition': 744,\n",
       " 'strongly': 745,\n",
       " 'paranoid': 746,\n",
       " 'wanting': 747,\n",
       " 'leave': 748,\n",
       " 'house': 749,\n",
       " 'laugh': 750,\n",
       " 'however': 751,\n",
       " 'suspicious': 752,\n",
       " 'definitely': 753,\n",
       " 'live': 754,\n",
       " 'forever': 755,\n",
       " 'stay': 756,\n",
       " 'until': 757,\n",
       " 'hit': 758,\n",
       " 'maybe': 759,\n",
       " 'bite': 760,\n",
       " 'thatd': 761,\n",
       " 'cool': 762,\n",
       " 'rich': 763,\n",
       " 'table': 764,\n",
       " 'took': 765,\n",
       " 'blurry': 766,\n",
       " 'captures': 767,\n",
       " 'relieved': 768,\n",
       " 'bliss': 769,\n",
       " 'told': 770,\n",
       " 'designer': 771,\n",
       " 'fitting': 772,\n",
       " 'belong': 773,\n",
       " 'friends': 774,\n",
       " 'aspirations': 775,\n",
       " 'plus': 776,\n",
       " 'eyes': 777,\n",
       " 'itch': 778,\n",
       " 'hot': 779,\n",
       " 'light': 780,\n",
       " 'nourishing': 781,\n",
       " 'skin': 782,\n",
       " 'amazing': 783,\n",
       " 'morning': 784,\n",
       " 'honoured': 785,\n",
       " 'introduce': 786,\n",
       " 'nice': 787,\n",
       " 'travelled': 788,\n",
       " 'stylish': 789,\n",
       " 'href': 790,\n",
       " 'http': 791,\n",
       " 'silkyway': 792,\n",
       " 'gentle': 793,\n",
       " 'www': 794,\n",
       " 'keep': 795,\n",
       " 'cards': 796,\n",
       " 'throw': 797,\n",
       " 'force': 798,\n",
       " 'disappointment': 799,\n",
       " 'rejected': 800,\n",
       " 'shield': 801,\n",
       " 'replace': 802,\n",
       " 'academia': 803,\n",
       " 'any': 804,\n",
       " 'whether': 805,\n",
       " 'dissatisfied': 806,\n",
       " 'hardening': 807,\n",
       " 'gorgeous': 808,\n",
       " 'breasts': 809,\n",
       " 'sucking': 810,\n",
       " 'ugly': 811,\n",
       " 'certainly': 812,\n",
       " 'act': 813,\n",
       " 'best': 814,\n",
       " 'whiney': 815,\n",
       " 'bitch': 816,\n",
       " 'become': 817,\n",
       " 'intelligent': 818,\n",
       " 'semester': 819,\n",
       " 'remember': 820,\n",
       " 'jaded': 821,\n",
       " 'after': 822,\n",
       " 'first': 823,\n",
       " 'abroad': 824,\n",
       " 'america': 825,\n",
       " 'betrayed': 826,\n",
       " 'somehow': 827,\n",
       " 'romantic': 828,\n",
       " 'couple': 829,\n",
       " 'free': 830,\n",
       " 'together': 831,\n",
       " 'putting': 832,\n",
       " 'nd': 833,\n",
       " 'class': 834,\n",
       " 'newly': 835,\n",
       " 'frocked': 836,\n",
       " 'interior': 837,\n",
       " 'communication': 838,\n",
       " 'electrician': 839,\n",
       " 'rachel': 840,\n",
       " 'rice': 841,\n",
       " 'knowledgeable': 842,\n",
       " 'stage': 843,\n",
       " 'attempt': 844,\n",
       " 'coloring': 845,\n",
       " 'session': 846,\n",
       " 'crazy': 847,\n",
       " 'saturday': 848,\n",
       " 'nights': 849,\n",
       " 'over': 850,\n",
       " 'valentines': 851,\n",
       " 'banquet': 852,\n",
       " 'tonight': 853,\n",
       " 'makeup': 854,\n",
       " 'anyone': 855,\n",
       " 'takes': 856,\n",
       " 'posts': 857,\n",
       " 'absolutely': 858,\n",
       " 'sufficed': 859,\n",
       " 'equally': 860,\n",
       " 'determined': 861,\n",
       " 'prom': 862,\n",
       " 'signalled': 863,\n",
       " 'gloomy': 864,\n",
       " 'clouds': 865,\n",
       " 'rainfall': 866,\n",
       " 'puppets': 867,\n",
       " 'obstacle': 868,\n",
       " 'distracting': 869,\n",
       " 'drama': 870,\n",
       " 'rather': 871,\n",
       " 'supporting': 872,\n",
       " 'adding': 873,\n",
       " 'threatened': 874,\n",
       " 'guys': 875,\n",
       " 'intruding': 876,\n",
       " 'vaguely': 877,\n",
       " 'lost': 878,\n",
       " 'pulled': 879,\n",
       " 'roadside': 880,\n",
       " 'forest': 881,\n",
       " 'sat': 882,\n",
       " 'under': 883,\n",
       " 'tree': 884,\n",
       " 'reminding': 885,\n",
       " 'destination': 886,\n",
       " 'sure': 887,\n",
       " 'invented': 888,\n",
       " 'brow': 889,\n",
       " 'beaten': 890,\n",
       " 'whenever': 891,\n",
       " 'bbc': 892,\n",
       " 'attack': 893,\n",
       " 'pumped': 894,\n",
       " 'mr': 895,\n",
       " 'lyons': 896,\n",
       " 'wordle': 897,\n",
       " 'weather': 898,\n",
       " 'worst': 899,\n",
       " 'effect': 900,\n",
       " 'difficult': 901,\n",
       " 'choose': 902,\n",
       " 'moody': 903,\n",
       " 'ryan': 904,\n",
       " 'made': 905,\n",
       " 'albino': 906,\n",
       " 'toned': 907,\n",
       " 'point': 908,\n",
       " 'turning': 909,\n",
       " 'grey': 910,\n",
       " 'skeptical': 911,\n",
       " 'hairdresser': 912,\n",
       " 'departed': 913,\n",
       " 'couldn': 914,\n",
       " 'attest': 915,\n",
       " 'particular': 916,\n",
       " 'reason': 917,\n",
       " 'experiencing': 918,\n",
       " 'erratic': 919,\n",
       " 'type': 920,\n",
       " 'emotions': 921,\n",
       " 'convince': 922,\n",
       " 'says': 923,\n",
       " 'vain': 924,\n",
       " 'receive': 925,\n",
       " 'letter': 926,\n",
       " 'nudge': 927,\n",
       " 'behind': 928,\n",
       " 'writing': 929,\n",
       " 'fall': 930,\n",
       " 'quarter': 931,\n",
       " 'decision': 932,\n",
       " 'overwork': 933,\n",
       " 'dawley': 934,\n",
       " 'text': 935,\n",
       " 'neither': 936,\n",
       " 'ought': 937,\n",
       " 'shaken': 938,\n",
       " 'small': 939,\n",
       " 'comments': 940,\n",
       " 'please': 941,\n",
       " 'buying': 942,\n",
       " 'shoes': 943,\n",
       " 'online': 944,\n",
       " 'sincere': 945,\n",
       " 'store': 946,\n",
       " 'bothered': 947,\n",
       " 'fact': 948,\n",
       " 'chances': 949,\n",
       " 'appreciation': 950,\n",
       " 'utter': 951,\n",
       " 'gratefulness': 952,\n",
       " 'downright': 953,\n",
       " 'souls': 954,\n",
       " 'change': 955,\n",
       " 'addiction': 956,\n",
       " 'sarcastic': 957,\n",
       " 'edge': 958,\n",
       " 'twinge': 959,\n",
       " 'esteem': 960,\n",
       " 'capabilities': 961,\n",
       " 'respected': 962,\n",
       " 'professional': 963,\n",
       " 'personal': 964,\n",
       " 'finally': 965,\n",
       " 'signed': 966,\n",
       " 'petition': 967,\n",
       " 'quit': 968,\n",
       " 'frantic': 969,\n",
       " 'smoke': 970,\n",
       " 'pleasant': 971,\n",
       " 'surprise': 972,\n",
       " 'inside': 973,\n",
       " 'calm': 974,\n",
       " 'held': 975,\n",
       " 'large': 976,\n",
       " 'wave': 977,\n",
       " 'drowning': 978,\n",
       " 'messy': 979,\n",
       " 'unmotivated': 980,\n",
       " 'captivating': 981,\n",
       " 'energetic': 982,\n",
       " 'motions': 983,\n",
       " 'euphoric': 984,\n",
       " 'advisable': 985,\n",
       " 'decide': 986,\n",
       " 'delighted': 987,\n",
       " 'fans': 988,\n",
       " 'paintings': 989,\n",
       " 'able': 990,\n",
       " 'body': 991,\n",
       " 'honored': 992,\n",
       " 'come': 993,\n",
       " 'queenie': 994,\n",
       " 'retire': 995,\n",
       " 'royal': 996,\n",
       " 'bedchamber': 997,\n",
       " 'seeing': 998,\n",
       " 'photography': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
